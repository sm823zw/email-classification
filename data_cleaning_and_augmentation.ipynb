{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import email\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Message-ID: &lt;23486926.1075842966554.JavaMail.e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Message-ID: &lt;18218267.1075862047342.JavaMail.e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Message-ID: &lt;15377587.1075846173597.JavaMail.e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Message-ID: &lt;17415116.1075863429863.JavaMail.e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Message-ID: &lt;26691844.1075852531386.JavaMail.e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Message-ID: &lt;30156147.1075849864036.JavaMail.e...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Message-ID: &lt;1421029.1075849864316.JavaMail.ev...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Message-ID: &lt;26990460.1075858882856.JavaMail.e...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Message-ID: &lt;11049182.1075858884165.JavaMail.e...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Message-ID: &lt;27574614.1075847593254.JavaMail.e...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1663 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    Message-ID: <23486926.1075842966554.JavaMail.e...      0\n",
       "1    Message-ID: <18218267.1075862047342.JavaMail.e...      0\n",
       "2    Message-ID: <15377587.1075846173597.JavaMail.e...      0\n",
       "3    Message-ID: <17415116.1075863429863.JavaMail.e...      0\n",
       "4    Message-ID: <26691844.1075852531386.JavaMail.e...      0\n",
       "..                                                 ...    ...\n",
       "138  Message-ID: <30156147.1075849864036.JavaMail.e...      5\n",
       "139  Message-ID: <1421029.1075849864316.JavaMail.ev...      5\n",
       "140  Message-ID: <26990460.1075858882856.JavaMail.e...      5\n",
       "141  Message-ID: <11049182.1075858884165.JavaMail.e...      5\n",
       "142  Message-ID: <27574614.1075847593254.JavaMail.e...      5\n",
       "\n",
       "[1663 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Read emails from the data folders\n",
    "path = 'enron_with_categories/'\n",
    "labels = []\n",
    "data = None\n",
    "for i in range(1, 7):\n",
    "    list_emails = []\n",
    "    dir_path = path + str(i) + '/'\n",
    "    for file_path in os.listdir(dir_path):\n",
    "        if '.txt' in file_path:\n",
    "            labels.append(i-1)\n",
    "            with open(dir_path + file_path, 'r', encoding=\"utf-8\") as file:\n",
    "                email_lines = file.read()\n",
    "                list_emails.append(email_lines)\n",
    "    d = pd.DataFrame()\n",
    "    d['text'] = list_emails\n",
    "    if data is None:\n",
    "        data = d\n",
    "    else:\n",
    "        data = pd.concat([data, d])\n",
    "data['label'] = labels\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the ratio of non-alphabet to alphabet characters in a line\n",
    "def compute_ratio(string):\n",
    "    # Initialize counters for non-alphabet and alphabet characters\n",
    "    non_alphabet_count = 0\n",
    "    alphabet_count = 0\n",
    "\n",
    "    # Iterate through each character in the string\n",
    "    for char in string:\n",
    "        if char.isalpha() or char in ['.', ',']:\n",
    "            alphabet_count += 1\n",
    "        else:\n",
    "            non_alphabet_count += 1\n",
    "\n",
    "    # Calculate the ratio\n",
    "    if alphabet_count == 0:\n",
    "        ratio = 100000000\n",
    "    else:\n",
    "        ratio = non_alphabet_count / alphabet_count\n",
    "\n",
    "    return ratio\n",
    "\n",
    "# Function to remove email addresses\n",
    "def remove_email_addresses(text):\n",
    "    # Define the regex pattern for matching email addresses\n",
    "    pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b'\n",
    "\n",
    "    # Use the findall function to find all email addresses in the text\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard lines with the following texts and whose compute_ratio is more than 0.3. \n",
    "discard = ['forwarded by', 'to:', 'cc:', 'subject', 'from:', 'sent:', '--']\n",
    "\n",
    "emails = []\n",
    "for email_text in data['text']:\n",
    "    msg = email.message_from_string(email_text)\n",
    "    payload = msg.get_payload()\n",
    "    payload = remove_email_addresses(payload)\n",
    "    ans = []\n",
    "    for line in payload.split('\\n'):\n",
    "        line = line.lower()\n",
    "        flag = 0\n",
    "        for phrase in discard:\n",
    "            if phrase in line:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 0 and len(line) > 0 and compute_ratio(line) < 0.3:\n",
    "            ans.append(line)\n",
    "    ans = ' '.join(ans)\n",
    "    if len(ans) == 0:\n",
    "        payload = re.sub(r'\\s+', ' ', payload).strip()\n",
    "        ans = payload\n",
    "    emails.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we will be asking for confidential treatment u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sent from my blackberry wireless handheld (www...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thaniks for the note.  christie is now organiz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear all, we have developed analytical souluti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in our july 30, 2001 document entitled \"receip...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>looks fine steve and cindy, attached is the el...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>steve: please review the attached ene officer ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>bonnie:  please forward to michael kirby. i th...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>my suggestions are attached. take the gloves o...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>anaya/hou/ect@ect, david andrews/corp/enron@en...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1663 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     we will be asking for confidential treatment u...      0\n",
       "1     sent from my blackberry wireless handheld (www...      0\n",
       "2     thaniks for the note.  christie is now organiz...      0\n",
       "3     dear all, we have developed analytical souluti...      0\n",
       "4     in our july 30, 2001 document entitled \"receip...      0\n",
       "...                                                 ...    ...\n",
       "1658  looks fine steve and cindy, attached is the el...      5\n",
       "1659  steve: please review the attached ene officer ...      5\n",
       "1660  bonnie:  please forward to michael kirby. i th...      5\n",
       "1661  my suggestions are attached. take the gloves o...      5\n",
       "1662  anaya/hou/ect@ect, david andrews/corp/enron@en...      5\n",
       "\n",
       "[1663 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the emails and their labels in a dataframe\n",
    "input_df = pd.DataFrame()\n",
    "input_df['text'] = emails\n",
    "input_df['label'] = labels\n",
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    834\n",
       "3    476\n",
       "5    143\n",
       "2    100\n",
       "4     74\n",
       "1     36\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check class distribution\n",
    "input_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To solve the issue of class imbalance, use back translation on minority classes to upsample them\n",
    "import nlpaug.augmenter.word as naw\n",
    "back_translation_aug = naw.BackTranslationAug(\n",
    "    from_model_name='facebook/wmt19-en-de', \n",
    "    to_model_name='facebook/wmt19-de-en'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = input_df\n",
    "\n",
    "# Split the data into training, validation, and test sets with stratification\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42, stratify=data['label'])\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42, stratify=test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    667\n",
       "3    381\n",
       "5    114\n",
       "2     80\n",
       "4     59\n",
       "1     29\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [2:01:01<00:00, 19.06s/it]  \n",
      "100%|██████████| 114/114 [38:55<00:00, 20.48s/it]\n",
      "100%|██████████| 114/114 [37:09<00:00, 19.56s/it]\n",
      "100%|██████████| 114/114 [36:32<00:00, 19.23s/it]\n",
      "100%|██████████| 114/114 [35:39<00:00, 18.77s/it]\n",
      "100%|██████████| 114/114 [36:42<00:00, 19.32s/it]\n",
      "100%|██████████| 80/80 [23:01<00:00, 17.27s/it]\n",
      "100%|██████████| 80/80 [22:32<00:00, 16.90s/it]\n",
      "100%|██████████| 80/80 [22:37<00:00, 16.96s/it]\n",
      "100%|██████████| 80/80 [23:16<00:00, 17.45s/it]\n",
      "100%|██████████| 80/80 [24:23<00:00, 18.29s/it]\n",
      "100%|██████████| 80/80 [22:24<00:00, 16.81s/it]\n",
      "100%|██████████| 80/80 [22:15<00:00, 16.69s/it]\n",
      "100%|██████████| 80/80 [22:58<00:00, 17.23s/it]\n",
      "100%|██████████| 59/59 [21:14<00:00, 21.59s/it]\n",
      "100%|██████████| 59/59 [20:58<00:00, 21.34s/it]\n",
      "100%|██████████| 59/59 [20:48<00:00, 21.15s/it]\n",
      "100%|██████████| 59/59 [20:41<00:00, 21.03s/it]\n",
      "100%|██████████| 59/59 [22:16<00:00, 22.66s/it]\n",
      "100%|██████████| 59/59 [23:14<00:00, 23.63s/it]\n",
      "100%|██████████| 59/59 [23:24<00:00, 23.81s/it]\n",
      "100%|██████████| 59/59 [21:08<00:00, 21.49s/it]\n",
      "100%|██████████| 59/59 [22:59<00:00, 23.38s/it]\n",
      "100%|██████████| 59/59 [24:00<00:00, 24.42s/it]\n",
      "100%|██████████| 59/59 [26:41<00:00, 27.15s/it]\n",
      "100%|██████████| 29/29 [11:03<00:00, 22.87s/it]\n",
      "100%|██████████| 29/29 [10:47<00:00, 22.34s/it]\n",
      "100%|██████████| 29/29 [10:56<00:00, 22.65s/it]\n",
      "100%|██████████| 29/29 [11:00<00:00, 22.79s/it]\n",
      "100%|██████████| 29/29 [10:52<00:00, 22.50s/it]\n",
      "100%|██████████| 29/29 [10:41<00:00, 22.12s/it]\n",
      "100%|██████████| 29/29 [10:44<00:00, 22.23s/it]\n",
      "100%|██████████| 29/29 [10:54<00:00, 22.57s/it]\n",
      "100%|██████████| 29/29 [11:03<00:00, 22.88s/it]\n",
      "100%|██████████| 29/29 [11:06<00:00, 22.99s/it]\n",
      "100%|██████████| 29/29 [11:02<00:00, 22.85s/it]\n",
      "100%|██████████| 29/29 [10:53<00:00, 22.52s/it]\n",
      "100%|██████████| 29/29 [10:43<00:00, 22.18s/it]\n",
      "100%|██████████| 29/29 [10:41<00:00, 22.13s/it]\n",
      "100%|██████████| 29/29 [10:33<00:00, 21.86s/it]\n",
      "100%|██████████| 29/29 [10:33<00:00, 21.84s/it]\n",
      "100%|██████████| 29/29 [10:23<00:00, 21.51s/it]\n",
      "100%|██████████| 29/29 [10:38<00:00, 22.01s/it]\n",
      "100%|██████████| 29/29 [10:34<00:00, 21.88s/it]\n",
      "100%|██████████| 29/29 [10:31<00:00, 21.76s/it]\n",
      "100%|██████████| 29/29 [10:26<00:00, 21.62s/it]\n",
      "100%|██████████| 29/29 [10:22<00:00, 21.45s/it]\n",
      "100%|██████████| 29/29 [10:23<00:00, 21.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    762\n",
       "2    720\n",
       "4    708\n",
       "1    696\n",
       "5    684\n",
       "0    667\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Augment minority class data\n",
    "count_dict = dict(train_data['label'].value_counts())\n",
    "max_count = max([v for k, v in count_dict.items()])\n",
    "add_dict = {}\n",
    "new_train_data = [train_data]\n",
    "for k in list(count_dict.keys()):\n",
    "    minority_resamples_count = max_count - count_dict[k]\n",
    "    minority_samples = []\n",
    "    labels = []\n",
    "    if minority_resamples_count != 0:\n",
    "        for i in range(int(max_count/count_dict[k])):\n",
    "            minority_class_text = train_data[train_data['label'] == k]['text'].tolist()\n",
    "            for text in tqdm.tqdm(minority_class_text):\n",
    "                text_to_augment = back_translation_aug.augment(text)\n",
    "                if len(text_to_augment) != 0:\n",
    "                    minority_samples.append(text_to_augment[0])\n",
    "                    labels.append(k)\n",
    "        minority_samples_df = pd.DataFrame()\n",
    "        minority_samples_df['text'] = minority_samples\n",
    "        minority_samples_df['label'] = labels\n",
    "        new_train_data.append(minority_samples_df)\n",
    "new_train_data = pd.concat(new_train_data, axis=0)\n",
    "new_train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new and the old training data and validation and test data\n",
    "new_train_data.to_csv('new_train_data.csv', index=None)\n",
    "train_data.to_csv('train_data.csv', index=None)\n",
    "val_data.to_csv('val_data.csv', index=None)\n",
    "test_data.to_csv('test_data.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39_native')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55605e6521e3f9193fe8f338668c37947d3ff2dbb1f9a55b107405982fa03566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
